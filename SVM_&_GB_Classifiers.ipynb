{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1igAwqjPNueFyPxWe_JVSqJKYWsCjpQKn",
      "authorship_tag": "ABX9TyOU2Fra0DG2+U/SpUUwpok5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullahiOlapojoye/Machine-Learning-based-Infants-Sucking-Patterns-Classification/blob/main/SVM_%26_GB_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# For the Visuals\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "from matplotlib import cm\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "from matplotlib.patches import Rectangle\n",
        "from IPython.display import display_html\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "import plotly.graph_objects as go\n",
        "#performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_auc_score,auc,f1_score\n",
        "from sklearn.metrics import precision_recall_curve,roc_curve"
      ],
      "metadata": {
        "id": "XQS_x5MzCHYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DATA PREPARATION**"
      ],
      "metadata": {
        "id": "8epTk3WHvxjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read and process CSV files\n",
        "def read_and_process_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Assuming the CSV file has columns \"feature1\" and \"feature2\"\n",
        "    data = df[['F1', 'F2']].values\n",
        "    return data\n",
        "\n",
        "# Function to read labels from the \"targets.csv\" file\n",
        "def read_labels_from_targets(targets_file_path):\n",
        "    df_targets = pd.read_csv(targets_file_path)\n",
        "    return df_targets.values  # Assuming the \"targets.csv\" file has a column named \"label\"\n",
        "\n",
        "# Function to generate time series data and labels from a list of CSV files\n",
        "def generate_data_from_csv(file_list, targets_file_path):\n",
        "    data_list = []\n",
        "\n",
        "    for file_path in file_list:\n",
        "        time_series_data = read_and_process_csv(file_path)\n",
        "        data_list.append(time_series_data)\n",
        "\n",
        "    labels = read_labels_from_targets(targets_file_path)\n",
        "\n",
        "    return np.array(data_list), np.array(labels)\n",
        "\n",
        "# Specify the path to your CSV files\n",
        "path1 = \"/content/drive/MyDrive/BMEN 6367/SENSOR_DATA_DL_m/Features/Subject_\"\n",
        "targets_file_path = \"/content/drive/MyDrive/BMEN 6367/SENSOR_DATA_DL_V2/Target/Target.csv\"\n",
        "#files\n",
        "csv_files = []\n",
        "for i in range(1,41):\n",
        "    file_path = path1 + str(i) + '.csv'\n",
        "    print(file_path)\n",
        "    csv_files.append(file_path)\n",
        "\n",
        "# Generate data and labels\n",
        "X, y = generate_data_from_csv(csv_files, targets_file_path)\n"
      ],
      "metadata": {
        "id": "_diwUyOWCLkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MODELLING WITH SVC**"
      ],
      "metadata": {
        "id": "hpNcWeSNvqWR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_h0LJAeB8iQ"
      },
      "outputs": [],
      "source": [
        "# Flatten the time series data\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "y = y.reshape(y.shape[0], -1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Standardize the data (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the SVM model\n",
        "svm_model = SVC(kernel='rbf', C=1.0)#, probability=True)\n",
        "\n",
        "# Define K-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(svm_model, X, y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
        "\n",
        "# Train the SVM model on the entire dataset\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "# X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Evaluation**"
      ],
      "metadata": {
        "id": "3XdmmkUZvhAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_SVM = svm_model.predict(X_train_scaled)\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_train, Train_SVM)\n",
        "print(f'Training Accuracy: {accuracy}')\n",
        "\n",
        "#Classification Report\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Recall score  =\",recall_score(y_test, y_pred))\n",
        "print(\"Precision score =\",precision_score(y_test, y_pred))\n",
        "print(\"Accuracy score  =\",accuracy_score(y_test, y_pred))\n",
        "print(\"F score  =\", f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Set1', xticklabels=['Healthy', 'Unhealthy'], yticklabels=['Healthy', 'Unhealthy'])\n",
        "plt.title('Confusion Matrix (SVC)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "# y_pred_auc = svm_model.predict_proba(X_test_scaled).flatten()\n",
        "y_pred_auc = svm_model.decision_function(X_test_scaled)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_auc)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e2xAI6Zkc1sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "-Je7d2uov76Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save the trained SVM model to a file\n",
        "model_svm = 'svm_model.joblib'\n",
        "joblib.dump(svm_model, model_svm)\n",
        "print(f\"SVM model saved to {model_svm}\")\n",
        "# # Load the saved SVM model\n",
        "# loaded_svm_model = joblib.load('svm_model.joblib')"
      ],
      "metadata": {
        "id": "ZZZaHCYk3EKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------\n",
        "------------------------------------------"
      ],
      "metadata": {
        "id": "Zm8KE9VhueGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GRADIENT BOOSTING CLASSIFIER**"
      ],
      "metadata": {
        "id": "6PITX35ouXUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradient Boosting Classifier model\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the model with the best hyperparameters on the entire training set\n",
        "best_gb_model = GradientBoostingClassifier(random_state=42, **best_params)\n",
        "best_gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_GB = best_gb_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred_GB)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, y_pred_GB))"
      ],
      "metadata": {
        "id": "WR702rFWjfGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Evaluation**"
      ],
      "metadata": {
        "id": "uygVvQ-cwOHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_GB = best_gb_model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred_GB))\n",
        "print(\"Recall score  =\",recall_score(y_test, y_pred_GB))\n",
        "print(\"Precision score =\",precision_score(y_test, y_pred_GB))\n",
        "print(\"Accuracy score  =\",accuracy_score(y_test, y_pred_GB))\n",
        "print(\"F score  =\", f1_score(y_test, y_pred_GB, average='weighted'))\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_GB)\n",
        "# Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Set1', xticklabels=['Healthy', 'Unhealthy'], yticklabels=['Healthy', 'Unhealthy'])\n",
        "plt.title('Confusion Matrix(GB)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "y_pred_GB_auc = best_gb_model.decision_function(X_test_scaled)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_GB)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pefbtjI6oCrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "Train_GB = best_gb_model.predict(X_train_scaled)\n",
        "accuracy = accuracy_score(y_train, Train_GB)\n",
        "print(f'Train Accuracy for GB: {accuracy}')"
      ],
      "metadata": {
        "id": "jmSFZ7LaqLNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save the trained SVM model to a file\n",
        "model_GB = 'GB_model.joblib'\n",
        "joblib.dump(best_gb_model, model_GB)\n",
        "print(f\"GB model saved to {model_GB}\")\n",
        "# # Load the saved SVM model\n",
        "# loaded_svm_model = joblib.load('svm_model.joblib')"
      ],
      "metadata": {
        "id": "CUd6ZcB_EHmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}